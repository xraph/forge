package cache

import (
	"context"
	"encoding/json"
	"fmt"
	"sync"
	"time"

	"github.com/xraph/forge/pkg/common"
	"github.com/xraph/forge/pkg/logger"
)

// AdvancedCache provides advanced caching functionality with multiple backends
type AdvancedCache struct {
	config   AdvancedCacheConfig
	backends map[string]CacheBackend
	mu       sync.RWMutex
	logger   common.Logger
	metrics  common.Metrics
	stats    CacheStats
}

// AdvancedCacheConfig contains advanced cache configuration
type AdvancedCacheConfig struct {
	DefaultBackend    string                   `yaml:"default_backend" default:"memory"`
	Backends          map[string]BackendConfig `yaml:"backends"`
	EnableMetrics     bool                     `yaml:"enable_metrics" default:"true"`
	EnableCompression bool                     `yaml:"enable_compression" default:"true"`
	CompressionLevel  int                      `yaml:"compression_level" default:"6"`
	EnableEncryption  bool                     `yaml:"enable_encryption" default:"false"`
	EncryptionKey     string                   `yaml:"encryption_key"`
	DefaultTTL        time.Duration            `yaml:"default_ttl" default:"1h"`
	MaxSize           int64                    `yaml:"max_size" default:"1000000"`
	CleanupInterval   time.Duration            `yaml:"cleanup_interval" default:"5m"`
	Logger            common.Logger            `yaml:"-"`
	Metrics           common.Metrics           `yaml:"-"`
}

// BackendConfig contains backend-specific configuration
type BackendConfig struct {
	Type       string            `yaml:"type"` // "memory", "redis", "memcached"
	Host       string            `yaml:"host"`
	Port       int               `yaml:"port"`
	Password   string            `yaml:"password"`
	Database   int               `yaml:"database"`
	PoolSize   int               `yaml:"pool_size" default:"10"`
	MaxRetries int               `yaml:"max_retries" default:"3"`
	Timeout    time.Duration     `yaml:"timeout" default:"5s"`
	Options    map[string]string `yaml:"options"`
}

// CacheBackend interface for different cache backends
type CacheBackend interface {
	Get(ctx context.Context, key string) (interface{}, error)
	Set(ctx context.Context, key string, value interface{}, ttl time.Duration) error
	Delete(ctx context.Context, key string) error
	Exists(ctx context.Context, key string) (bool, error)
	Clear(ctx context.Context) error
	GetStats() CacheBackendStats
	Close() error
}

// CacheStats represents cache statistics
type CacheStats struct {
	TotalRequests  int64         `json:"total_requests"`
	HitRequests    int64         `json:"hit_requests"`
	MissRequests   int64         `json:"miss_requests"`
	SetRequests    int64         `json:"set_requests"`
	DeleteRequests int64         `json:"delete_requests"`
	ClearRequests  int64         `json:"clear_requests"`
	ErrorRequests  int64         `json:"error_requests"`
	TotalSize      int64         `json:"total_size"`
	LastAccess     time.Time     `json:"last_access"`
	LastHit        time.Time     `json:"last_hit"`
	LastMiss       time.Time     `json:"last_miss"`
	HitRate        float64       `json:"hit_rate"`
	AverageLatency time.Duration `json:"average_latency"`
}

// CacheBackendStats represents backend-specific statistics
type CacheBackendStats struct {
	BackendType    string        `json:"backend_type"`
	TotalRequests  int64         `json:"total_requests"`
	HitRequests    int64         `json:"hit_requests"`
	MissRequests   int64         `json:"miss_requests"`
	ErrorRequests  int64         `json:"error_requests"`
	TotalSize      int64         `json:"total_size"`
	ConnectionPool int           `json:"connection_pool"`
	LastAccess     time.Time     `json:"last_access"`
	HitRate        float64       `json:"hit_rate"`
	AverageLatency time.Duration `json:"average_latency"`
}

// CacheItem represents a cached item
type CacheItem struct {
	Key         string        `json:"key"`
	Value       interface{}   `json:"value"`
	TTL         time.Duration `json:"ttl"`
	CreatedAt   time.Time     `json:"created_at"`
	ExpiresAt   time.Time     `json:"expires_at"`
	AccessCount int64         `json:"access_count"`
	LastAccess  time.Time     `json:"last_access"`
	Size        int64         `json:"size"`
}

// CacheManager provides cache management functionality
type CacheManager struct {
	config  CacheManagerConfig
	logger  common.Logger
	metrics common.Metrics
	caches  map[string]CacheBackend
	mu      sync.RWMutex
}

// CacheBackendConfig contains configuration for cache backends
type CacheBackendConfig struct {
	Type    string                 `yaml:"type"`
	Config  map[string]interface{} `yaml:"config"`
	Options map[string]string      `yaml:"options"`
}

// CacheManagerConfig contains configuration for the cache manager
type CacheManagerConfig struct {
	DefaultCache string                        `yaml:"default_cache"`
	Caches       map[string]CacheBackendConfig `yaml:"caches"`
}

// NewCacheManager creates a new cache manager
func NewCacheManager(config *CacheManagerConfig, logger common.Logger, metrics common.Metrics) *CacheManager {
	return &CacheManager{
		config:  *config,
		logger:  logger,
		metrics: metrics,
		caches:  make(map[string]CacheBackend),
	}
}

// NewAdvancedCache creates a new advanced cache
func NewAdvancedCache(config AdvancedCacheConfig) *AdvancedCache {
	if config.Logger == nil {
		config.Logger = logger.NewLogger(logger.LoggingConfig{Level: "info"})
	}

	cache := &AdvancedCache{
		config:   config,
		backends: make(map[string]CacheBackend),
		logger:   config.Logger,
		metrics:  config.Metrics,
		stats: CacheStats{
			LastAccess: time.Now(),
		},
	}

	// Initialize backends
	if err := cache.initializeBackends(); err != nil {
		cache.logger.Error("failed to initialize backends", logger.String("error", err.Error()))
	}

	// Start cleanup goroutine
	if config.CleanupInterval > 0 {
		go cache.startCleanup()
	}

	return cache
}

// initializeBackends initializes cache backends
func (ac *AdvancedCache) initializeBackends() error {
	for name, backendConfig := range ac.config.Backends {
		backend, err := ac.createBackend(name, backendConfig)
		if err != nil {
			return fmt.Errorf("failed to create backend %s: %w", name, err)
		}

		ac.backends[name] = backend
		ac.logger.Info("cache backend initialized",
			logger.String("name", name),
			logger.String("type", backendConfig.Type))
	}

	return nil
}

// createBackend creates a backend based on configuration
func (ac *AdvancedCache) createBackend(name string, config BackendConfig) (CacheBackend, error) {
	switch config.Type {
	case "memory":
		return NewMemoryBackend(config), nil
	case "redis":
		return NewRedisBackend(config), nil
	case "memcached":
		return NewMemcachedBackend(config), nil
	default:
		return nil, fmt.Errorf("unsupported backend type: %s", config.Type)
	}
}

// Get retrieves a value from the cache
func (ac *AdvancedCache) Get(ctx context.Context, key string) (interface{}, error) {
	start := time.Now()
	ac.stats.TotalRequests++
	ac.stats.LastAccess = time.Now()

	backend, err := ac.getBackend()
	if err != nil {
		ac.recordError()
		return nil, err
	}

	value, err := backend.Get(ctx, key)
	if err != nil {
		ac.recordMiss()
		return nil, err
	}

	ac.recordHit()
	ac.recordLatency(time.Since(start))

	// Record metrics
	if ac.config.EnableMetrics && ac.metrics != nil {
		ac.recordGetMetrics(key, time.Since(start), true)
	}

	return value, nil
}

// Set stores a value in the cache
func (ac *AdvancedCache) Set(ctx context.Context, key string, value interface{}, ttl time.Duration) error {
	start := time.Now()
	ac.stats.SetRequests++

	backend, err := ac.getBackend()
	if err != nil {
		ac.recordError()
		return err
	}

	// Use default TTL if not specified
	if ttl <= 0 {
		ttl = ac.config.DefaultTTL
	}

	// Process value (compression, encryption)
	processedValue, err := ac.processValue(value)
	if err != nil {
		ac.recordError()
		return fmt.Errorf("failed to process value: %w", err)
	}

	err = backend.Set(ctx, key, processedValue, ttl)
	if err != nil {
		ac.recordError()
		return err
	}

	ac.recordLatency(time.Since(start))

	// Record metrics
	if ac.config.EnableMetrics && ac.metrics != nil {
		ac.recordSetMetrics(key, time.Since(start), true)
	}

	return nil
}

// Delete removes a value from the cache
func (ac *AdvancedCache) Delete(ctx context.Context, key string) error {
	start := time.Now()
	ac.stats.DeleteRequests++

	backend, err := ac.getBackend()
	if err != nil {
		ac.recordError()
		return err
	}

	err = backend.Delete(ctx, key)
	if err != nil {
		ac.recordError()
		return err
	}

	ac.recordLatency(time.Since(start))

	// Record metrics
	if ac.config.EnableMetrics && ac.metrics != nil {
		ac.recordDeleteMetrics(key, time.Since(start), true)
	}

	return nil
}

// Exists checks if a key exists in the cache
func (ac *AdvancedCache) Exists(ctx context.Context, key string) (bool, error) {
	backend, err := ac.getBackend()
	if err != nil {
		return false, err
	}

	return backend.Exists(ctx, key)
}

// Clear clears all values from the cache
func (ac *AdvancedCache) Clear(ctx context.Context) error {
	start := time.Now()
	ac.stats.ClearRequests++

	backend, err := ac.getBackend()
	if err != nil {
		ac.recordError()
		return err
	}

	err = backend.Clear(ctx)
	if err != nil {
		ac.recordError()
		return err
	}

	ac.recordLatency(time.Since(start))

	// Record metrics
	if ac.config.EnableMetrics && ac.metrics != nil {
		ac.recordClearMetrics(time.Since(start), true)
	}

	return nil
}

// getBackend gets the default backend
func (ac *AdvancedCache) getBackend() (CacheBackend, error) {
	ac.mu.RLock()
	defer ac.mu.RUnlock()

	backend, exists := ac.backends[ac.config.DefaultBackend]
	if !exists {
		return nil, fmt.Errorf("backend %s not found", ac.config.DefaultBackend)
	}

	return backend, nil
}

// processValue processes a value for storage (compression, encryption)
func (ac *AdvancedCache) processValue(value interface{}) (interface{}, error) {
	// Serialize to JSON
	data, err := json.Marshal(value)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal value: %w", err)
	}

	// Compress if enabled
	if ac.config.EnableCompression {
		compressed, err := ac.compress(data)
		if err != nil {
			return nil, fmt.Errorf("failed to compress value: %w", err)
		}
		data = compressed
	}

	// Encrypt if enabled
	if ac.config.EnableEncryption {
		encrypted, err := ac.encrypt(data)
		if err != nil {
			return nil, fmt.Errorf("failed to encrypt value: %w", err)
		}
		data = encrypted
	}

	return data, nil
}

// compress compresses data
func (ac *AdvancedCache) compress(data []byte) ([]byte, error) {
	// Simple compression - in production, use proper compression
	return data, nil
}

// encrypt encrypts data
func (ac *AdvancedCache) encrypt(data []byte) ([]byte, error) {
	// Simple encryption - in production, use proper encryption
	return data, nil
}

// recordHit records a cache hit
func (ac *AdvancedCache) recordHit() {
	ac.stats.HitRequests++
	ac.stats.LastHit = time.Now()
	ac.updateHitRate()
}

// recordMiss records a cache miss
func (ac *AdvancedCache) recordMiss() {
	ac.stats.MissRequests++
	ac.stats.LastMiss = time.Now()
	ac.updateHitRate()
}

// recordError records a cache error
func (ac *AdvancedCache) recordError() {
	ac.stats.ErrorRequests++
}

// recordLatency records cache latency
func (ac *AdvancedCache) recordLatency(latency time.Duration) {
	ac.stats.AverageLatency = (ac.stats.AverageLatency + latency) / 2
}

// updateHitRate updates the hit rate
func (ac *AdvancedCache) updateHitRate() {
	total := ac.stats.HitRequests + ac.stats.MissRequests
	if total > 0 {
		ac.stats.HitRate = float64(ac.stats.HitRequests) / float64(total)
	}
}

// recordGetMetrics records get operation metrics
func (ac *AdvancedCache) recordGetMetrics(key string, latency time.Duration, success bool) {
	result := "success"
	if !success {
		result = "error"
	}

	ac.metrics.Counter("cache_get_total", "backend", ac.config.DefaultBackend, "result", result).Inc()

	ac.metrics.Histogram("cache_get_duration_seconds", "backend", ac.config.DefaultBackend, "result", result).Observe(latency.Seconds())
}

// recordSetMetrics records set operation metrics
func (ac *AdvancedCache) recordSetMetrics(key string, latency time.Duration, success bool) {
	result := "success"
	if !success {
		result = "error"
	}

	ac.metrics.Counter("cache_set_total", "backend", ac.config.DefaultBackend, "result", result).Inc()

	ac.metrics.Histogram("cache_set_duration_seconds", "backend", ac.config.DefaultBackend, "result", result).Observe(latency.Seconds())
}

// recordDeleteMetrics records delete operation metrics
func (ac *AdvancedCache) recordDeleteMetrics(key string, latency time.Duration, success bool) {
	result := "success"
	if !success {
		result = "error"
	}

	ac.metrics.Counter("cache_delete_total", "backend", ac.config.DefaultBackend, "result", result).Inc()

	ac.metrics.Histogram("cache_delete_duration_seconds", "backend", ac.config.DefaultBackend, "result", result).Observe(latency.Seconds())
}

// recordClearMetrics records clear operation metrics
func (ac *AdvancedCache) recordClearMetrics(latency time.Duration, success bool) {
	result := "success"
	if !success {
		result = "error"
	}

	ac.metrics.Counter("cache_clear_total", "backend", ac.config.DefaultBackend, "result", result).Inc()

	ac.metrics.Histogram("cache_clear_duration_seconds", "backend", ac.config.DefaultBackend, "result", result).Observe(latency.Seconds())
}

// startCleanup starts the cleanup goroutine
func (ac *AdvancedCache) startCleanup() {
	ticker := time.NewTicker(ac.config.CleanupInterval)
	defer ticker.Stop()

	for range ticker.C {
		ac.cleanup()
	}
}

// cleanup performs cache cleanup
func (ac *AdvancedCache) cleanup() {
	ac.logger.Info("performing cache cleanup")
	// Simple cleanup - in production, implement proper cleanup logic
}

// GetStats returns cache statistics
func (ac *AdvancedCache) GetStats() CacheStats {
	ac.mu.RLock()
	defer ac.mu.RUnlock()
	return ac.stats
}

// GetBackendStats returns backend statistics
func (ac *AdvancedCache) GetBackendStats() map[string]CacheBackendStats {
	ac.mu.RLock()
	defer ac.mu.RUnlock()

	stats := make(map[string]CacheBackendStats)
	for name, backend := range ac.backends {
		stats[name] = backend.GetStats()
	}

	return stats
}

// Close closes the cache
func (ac *AdvancedCache) Close() error {
	ac.mu.Lock()
	defer ac.mu.Unlock()

	for name, backend := range ac.backends {
		if err := backend.Close(); err != nil {
			ac.logger.Error("failed to close backend",
				logger.String("name", name),
				logger.String("error", err.Error()))
		}
	}

	return nil
}

// Built-in cache backends

// MemoryBackend provides in-memory caching
type MemoryBackend struct {
	config BackendConfig
	items  map[string]*CacheItem
	mu     sync.RWMutex
	stats  CacheBackendStats
}

func NewMemoryBackend(config BackendConfig) *MemoryBackend {
	return &MemoryBackend{
		config: config,
		items:  make(map[string]*CacheItem),
		stats: CacheBackendStats{
			BackendType: "memory",
		},
	}
}

func (mb *MemoryBackend) Get(ctx context.Context, key string) (interface{}, error) {
	mb.mu.RLock()
	defer mb.mu.RUnlock()

	item, exists := mb.items[key]
	if !exists {
		mb.stats.MissRequests++
		return nil, fmt.Errorf("key not found")
	}

	// Check expiration
	if time.Now().After(item.ExpiresAt) {
		delete(mb.items, key)
		mb.stats.MissRequests++
		return nil, fmt.Errorf("key expired")
	}

	// Update access statistics
	item.AccessCount++
	item.LastAccess = time.Now()
	mb.stats.HitRequests++
	mb.stats.LastAccess = time.Now()

	return item.Value, nil
}

func (mb *MemoryBackend) Set(ctx context.Context, key string, value interface{}, ttl time.Duration) error {
	mb.mu.Lock()
	defer mb.mu.Unlock()

	item := &CacheItem{
		Key:         key,
		Value:       value,
		TTL:         ttl,
		CreatedAt:   time.Now(),
		ExpiresAt:   time.Now().Add(ttl),
		AccessCount: 0,
		LastAccess:  time.Now(),
		Size:        int64(len(fmt.Sprintf("%v", value))),
	}

	mb.items[key] = item
	mb.stats.TotalRequests++
	mb.stats.TotalSize += item.Size

	return nil
}

func (mb *MemoryBackend) Delete(ctx context.Context, key string) error {
	mb.mu.Lock()
	defer mb.mu.Unlock()

	if item, exists := mb.items[key]; exists {
		mb.stats.TotalSize -= item.Size
		delete(mb.items, key)
	}

	return nil
}

func (mb *MemoryBackend) Exists(ctx context.Context, key string) (bool, error) {
	mb.mu.RLock()
	defer mb.mu.RUnlock()

	item, exists := mb.items[key]
	if !exists {
		return false, nil
	}

	// Check expiration
	if time.Now().After(item.ExpiresAt) {
		return false, nil
	}

	return true, nil
}

func (mb *MemoryBackend) Clear(ctx context.Context) error {
	mb.mu.Lock()
	defer mb.mu.Unlock()

	mb.items = make(map[string]*CacheItem)
	mb.stats.TotalSize = 0

	return nil
}

func (mb *MemoryBackend) GetStats() CacheBackendStats {
	mb.mu.RLock()
	defer mb.mu.RUnlock()

	mb.stats.HitRate = float64(mb.stats.HitRequests) / float64(mb.stats.HitRequests+mb.stats.MissRequests)
	return mb.stats
}

func (mb *MemoryBackend) Close() error {
	return nil
}

// RedisBackend provides Redis caching
type RedisBackend struct {
	config BackendConfig
	stats  CacheBackendStats
}

func NewRedisBackend(config BackendConfig) *RedisBackend {
	return &RedisBackend{
		config: config,
		stats: CacheBackendStats{
			BackendType: "redis",
		},
	}
}

func (rb *RedisBackend) Get(ctx context.Context, key string) (interface{}, error) {
	// Simple Redis implementation - in production, use proper Redis client
	rb.stats.TotalRequests++
	rb.stats.MissRequests++
	return nil, fmt.Errorf("Redis not implemented")
}

func (rb *RedisBackend) Set(ctx context.Context, key string, value interface{}, ttl time.Duration) error {
	// Simple Redis implementation - in production, use proper Redis client
	rb.stats.TotalRequests++
	return nil
}

func (rb *RedisBackend) Delete(ctx context.Context, key string) error {
	// Simple Redis implementation - in production, use proper Redis client
	rb.stats.TotalRequests++
	return nil
}

func (rb *RedisBackend) Exists(ctx context.Context, key string) (bool, error) {
	// Simple Redis implementation - in production, use proper Redis client
	rb.stats.TotalRequests++
	return false, nil
}

func (rb *RedisBackend) Clear(ctx context.Context) error {
	// Simple Redis implementation - in production, use proper Redis client
	rb.stats.TotalRequests++
	return nil
}

func (rb *RedisBackend) GetStats() CacheBackendStats {
	return rb.stats
}

func (rb *RedisBackend) Close() error {
	return nil
}

// MemcachedBackend provides Memcached caching
type MemcachedBackend struct {
	config BackendConfig
	stats  CacheBackendStats
}

func NewMemcachedBackend(config BackendConfig) *MemcachedBackend {
	return &MemcachedBackend{
		config: config,
		stats: CacheBackendStats{
			BackendType: "memcached",
		},
	}
}

func (mb *MemcachedBackend) Get(ctx context.Context, key string) (interface{}, error) {
	// Simple Memcached implementation - in production, use proper Memcached client
	mb.stats.TotalRequests++
	mb.stats.MissRequests++
	return nil, fmt.Errorf("Memcached not implemented")
}

func (mb *MemcachedBackend) Set(ctx context.Context, key string, value interface{}, ttl time.Duration) error {
	// Simple Memcached implementation - in production, use proper Memcached client
	mb.stats.TotalRequests++
	return nil
}

func (mb *MemcachedBackend) Delete(ctx context.Context, key string) error {
	// Simple Memcached implementation - in production, use proper Memcached client
	mb.stats.TotalRequests++
	return nil
}

func (mb *MemcachedBackend) Exists(ctx context.Context, key string) (bool, error) {
	// Simple Memcached implementation - in production, use proper Memcached client
	mb.stats.TotalRequests++
	return false, nil
}

func (mb *MemcachedBackend) Clear(ctx context.Context) error {
	// Simple Memcached implementation - in production, use proper Memcached client
	mb.stats.TotalRequests++
	return nil
}

func (mb *MemcachedBackend) GetStats() CacheBackendStats {
	return mb.stats
}

func (mb *MemcachedBackend) Close() error {
	return nil
}
