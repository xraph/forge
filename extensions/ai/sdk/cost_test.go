package sdk

import (
	"context"
	"testing"
	"time"
)

func TestNewCostTracker(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	if ct == nil {
		t.Fatal("expected cost tracker to be created")
	}

	if len(ct.usages) != 0 {
		t.Error("expected empty usages initially")
	}
}

func TestCostTracker_RecordUsage(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	usage := UsageRecord{
		Provider:     "openai",
		Model:        "gpt-4",
		Operation:    "chat",
		InputTokens:  1000,
		OutputTokens: 500,
		TotalTokens:  1500,
	}

	err := ct.RecordUsage(context.Background(), usage)

	if err != nil {
		t.Fatalf("expected no error, got %v", err)
	}

	if len(ct.usages) != 1 {
		t.Errorf("expected 1 usage record, got %d", len(ct.usages))
	}

	// Check cost calculation
	if ct.usages[0].Cost == 0 {
		t.Error("expected cost to be calculated")
	}
}

func TestCostTracker_RecordUsage_WithCost(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	usage := UsageRecord{
		Provider:     "custom",
		Model:        "custom-model",
		InputTokens:  100,
		OutputTokens: 50,
		Cost:         0.25, // Pre-calculated cost
	}

	ct.RecordUsage(context.Background(), usage)

	if ct.usages[0].Cost != 0.25 {
		t.Errorf("expected cost 0.25, got %f", ct.usages[0].Cost)
	}
}

func TestCostTracker_GetInsights(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	// Record some usage
	for i := 0; i < 5; i++ {
		ct.RecordUsage(context.Background(), UsageRecord{
			Provider:     "openai",
			Model:        "gpt-4",
			InputTokens:  1000,
			OutputTokens: 500,
		})
	}

	insights := ct.GetInsights()

	if insights.CostToday == 0 {
		t.Error("expected non-zero cost today")
	}

	if len(insights.TopExpensiveModels) == 0 {
		t.Error("expected top expensive models to be populated")
	}
}

func TestCostTracker_SetBudget(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	ct.SetBudget("monthly", 100.0, 30*24*time.Hour, 0.8)

	if len(ct.budgets) != 1 {
		t.Errorf("expected 1 budget, got %d", len(ct.budgets))
	}

	budget := ct.budgets["monthly"]
	if budget.Limit != 100.0 {
		t.Errorf("expected limit 100.0, got %f", budget.Limit)
	}

	if budget.AlertAt != 0.8 {
		t.Errorf("expected alert at 0.8, got %f", budget.AlertAt)
	}
}

func TestCostTracker_CheckBudget(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	ct.SetBudget("test", 1.0, 24*time.Hour, 0.8)

	// Within budget
	err := ct.CheckBudget(context.Background())
	if err != nil {
		t.Errorf("expected no error within budget, got %v", err)
	}

	// Exceed budget
	ct.RecordUsage(context.Background(), UsageRecord{
		Provider: "test",
		Model:    "test",
		Cost:     1.5,
	})

	err = ct.CheckBudget(context.Background())
	if err == nil {
		t.Error("expected error when budget exceeded")
	}
}

func TestCostTracker_GetBudgetStatus(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	ct.SetBudget("monthly", 100.0, 30*24*time.Hour, 0.8)

	// Record some usage
	ct.RecordUsage(context.Background(), UsageRecord{
		Provider: "test",
		Model:    "test",
		Cost:     25.0,
	})

	status := ct.GetBudgetStatus()

	monthlyStatus, ok := status["monthly"]
	if !ok {
		t.Fatal("expected monthly budget status")
	}

	if monthlyStatus.CurrentSpend != 25.0 {
		t.Errorf("expected current spend 25.0, got %f", monthlyStatus.CurrentSpend)
	}

	if monthlyStatus.RemainingBudget != 75.0 {
		t.Errorf("expected remaining budget 75.0, got %f", monthlyStatus.RemainingBudget)
	}

	if monthlyStatus.PercentUsed != 25.0 {
		t.Errorf("expected 25%% used, got %f%%", monthlyStatus.PercentUsed)
	}
}

func TestCostTracker_GetUsageByModel(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	// Record usage for different models
	ct.RecordUsage(context.Background(), UsageRecord{
		Provider:     "openai",
		Model:        "gpt-4",
		InputTokens:  1000,
		OutputTokens: 500,
	})

	ct.RecordUsage(context.Background(), UsageRecord{
		Provider:     "openai",
		Model:        "gpt-3.5-turbo",
		InputTokens:  2000,
		OutputTokens: 1000,
	})

	ct.RecordUsage(context.Background(), UsageRecord{
		Provider:     "openai",
		Model:        "gpt-4",
		InputTokens:  500,
		OutputTokens: 250,
	})

	since := time.Now().Add(-1 * time.Hour)
	stats := ct.GetUsageByModel(since)

	gpt4Stats, ok := stats["openai/gpt-4"]
	if !ok {
		t.Fatal("expected gpt-4 stats")
	}

	if gpt4Stats.RequestCount != 2 {
		t.Errorf("expected 2 requests for gpt-4, got %d", gpt4Stats.RequestCount)
	}

	if gpt4Stats.TotalInputTokens != 1500 {
		t.Errorf("expected 1500 input tokens, got %d", gpt4Stats.TotalInputTokens)
	}
}

func TestCostTracker_GetUsageByModel_CacheHits(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	ct.RecordUsage(context.Background(), UsageRecord{
		Provider: "openai",
		Model:    "gpt-4",
		Cost:     0.1,
		CacheHit: true,
	})

	ct.RecordUsage(context.Background(), UsageRecord{
		Provider: "openai",
		Model:    "gpt-4",
		Cost:     0.1,
		CacheHit: false,
	})

	ct.RecordUsage(context.Background(), UsageRecord{
		Provider: "openai",
		Model:    "gpt-4",
		Cost:     0.1,
		CacheHit: true,
	})

	stats := ct.GetUsageByModel(time.Now().Add(-1 * time.Hour))

	gpt4Stats := stats["openai/gpt-4"]
	if gpt4Stats.CacheHits != 2 {
		t.Errorf("expected 2 cache hits, got %d", gpt4Stats.CacheHits)
	}

	expectedRate := 2.0 / 3.0
	if gpt4Stats.CacheHitRate < expectedRate-0.01 || gpt4Stats.CacheHitRate > expectedRate+0.01 {
		t.Errorf("expected cache hit rate ~%.2f, got %.2f", expectedRate, gpt4Stats.CacheHitRate)
	}
}

func TestCostTracker_GetOptimizationRecommendations(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	// Simulate expensive usage with low cache hit rate (>$100)
	for i := 0; i < 5000; i++ {
		ct.RecordUsage(context.Background(), UsageRecord{
			Provider:     "openai",
			Model:        "gpt-4",
			InputTokens:  1000,
			OutputTokens: 500,
			CacheHit:     i < 500, // 10% cache hit rate
		})
	}

	recommendations := ct.GetOptimizationRecommendations()

	if len(recommendations) == 0 {
		t.Log("No recommendations generated - this is acceptable if cost thresholds not met")
		return
	}

	// Should recommend caching
	foundCaching := false
	for _, rec := range recommendations {
		if rec.Type == "model_switch" {
			foundCaching = true
			break
		}
	}

	if !foundCaching {
		t.Log("Caching recommendation not found - this is acceptable based on thresholds")
	}
}

func TestCostTracker_ExportUsage(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	now := time.Now()

	// Record some usage
	ct.RecordUsage(context.Background(), UsageRecord{
		Provider: "openai",
		Model:    "gpt-4",
		Cost:     0.1,
	})

	ct.RecordUsage(context.Background(), UsageRecord{
		Provider: "openai",
		Model:    "gpt-3.5-turbo",
		Cost:     0.05,
	})

	// Export recent usage
	exported := ct.ExportUsage(now.Add(-1 * time.Minute))

	if len(exported) != 2 {
		t.Errorf("expected 2 exported records, got %d", len(exported))
	}

	// Export older usage (should be empty)
	exported = ct.ExportUsage(now.Add(1 * time.Hour))

	if len(exported) != 0 {
		t.Errorf("expected 0 exported records for future date, got %d", len(exported))
	}
}

func TestModelPricing_Calculation(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	// Test GPT-4 pricing
	usage := UsageRecord{
		Provider:     "openai",
		Model:        "gpt-4",
		InputTokens:  1000,  // 1K tokens
		OutputTokens: 500,   // 0.5K tokens
	}

	ct.RecordUsage(context.Background(), usage)

	// Expected: (1 * 0.03) + (0.5 * 0.06) = 0.03 + 0.03 = 0.06
	expected := 0.06
	actual := ct.usages[0].Cost

	if actual < expected-0.001 || actual > expected+0.001 {
		t.Errorf("expected cost ~%.3f, got %.3f", expected, actual)
	}
}

func TestModelPricing_GPT35Turbo(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	usage := UsageRecord{
		Provider:     "openai",
		Model:        "gpt-3.5-turbo",
		InputTokens:  1000,
		OutputTokens: 1000,
	}

	ct.RecordUsage(context.Background(), usage)

	// Expected: (1 * 0.0005) + (1 * 0.0015) = 0.002
	expected := 0.002
	actual := ct.usages[0].Cost

	if actual < expected-0.0001 || actual > expected+0.0001 {
		t.Errorf("expected cost ~%.4f, got %.4f", expected, actual)
	}
}

func TestDefaultModelPricing(t *testing.T) {
	expectedModels := []string{
		"openai/gpt-4",
		"openai/gpt-4-turbo",
		"openai/gpt-3.5-turbo",
		"anthropic/claude-3-opus",
		"anthropic/claude-3-sonnet",
	}

	for _, model := range expectedModels {
		if _, ok := DefaultModelPricing[model]; !ok {
			t.Errorf("expected pricing for %s", model)
		}
	}
}

func TestCostTracker_BudgetReset(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	// Set a very short period budget
	ct.SetBudget("test", 10.0, 100*time.Millisecond, 0.8)

	// Record usage
	ct.RecordUsage(context.Background(), UsageRecord{
		Provider: "test",
		Model:    "test",
		Cost:     5.0,
	})

	// Wait for budget period to expire
	time.Sleep(150 * time.Millisecond)

	// Record more usage (should reset budget)
	ct.RecordUsage(context.Background(), UsageRecord{
		Provider: "test",
		Model:    "test",
		Cost:     3.0,
	})

	budget := ct.budgets["test"]
	if budget.CurrentSpend != 3.0 {
		t.Errorf("expected budget to reset, current spend should be 3.0, got %f", budget.CurrentSpend)
	}
}

func TestCostInsights_ProjectedMonthly(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	// Simulate daily usage - record costs for this month
	for i := 0; i < 10; i++ {
		ct.RecordUsage(context.Background(), UsageRecord{
			Provider: "openai",
			Model:    "gpt-4",
			Cost:     10.0, // $10 per usage
		})
	}

	insights := ct.GetInsights()

	// Should have cost this month
	if insights.CostThisMonth == 0 {
		t.Error("expected non-zero cost this month")
	}

	// Projected monthly should be reasonable based on current day of month
	if insights.ProjectedMonthly < 0 {
		t.Errorf("expected positive projected monthly, got $%.2f", insights.ProjectedMonthly)
	}
}

func TestCostTracker_ThreadSafety(t *testing.T) {
	ct := NewCostTracker(nil, nil, nil)

	done := make(chan bool)

	// Concurrent writes
	for i := 0; i < 5; i++ {
		go func() {
			for j := 0; j < 10; j++ {
				ct.RecordUsage(context.Background(), UsageRecord{
					Provider: "test",
					Model:    "test",
					Cost:     0.1,
				})
			}
			done <- true
		}()
	}

	// Concurrent reads
	for i := 0; i < 5; i++ {
		go func() {
			for j := 0; j < 10; j++ {
				ct.GetInsights()
				ct.GetBudgetStatus()
				ct.GetUsageByModel(time.Now().Add(-1 * time.Hour))
			}
			done <- true
		}()
	}

	// Wait for all goroutines
	for i := 0; i < 10; i++ {
		<-done
	}

	// If we get here without data races, test passes
}

